Virtual Actor
=============

by Carlos Sanchez Witt.

Description
===========

Master Semester Project II, SINLAB/LDM, EPFL.

The goal of this project is to build an emotive virtual actor through implementation of expressive voice synthesis and lip synced mouth animation.

The project is divided in three aspects:

* Text input: the source of speech content, which can be existing literature (formatted for expressive reading), or a social channel with active participation (a Twitter feed for instance).
* Audio output: the voice of the system. The right TTS system must be found for the best emotive speech synthesis.
* Video output: the visual mouth animation, synced to the audio, as a visual stimulus in place of a physical, real actor.

For more information read the wiki at:
https://github.com/sinlab-semester-2013/VirtualActor/wiki

Contents
--------

- VirtualActorJavaProject: application code (Eclipse project)
- marytts: MaryTTS Source Code (Eclipse projects)
- maryxml-input: MaryXML formatted texts for reading by the application

Setup and Dependencies
----------------------

Requires Eclipse/Java, and importing all projects into workspace.

Running Instructions
====================

Run VirtualActorJavaProject from within Eclipse.

Development Status
------------------

See Development Journal at:
https://github.com/sinlab-semester-2013/VirtualActor/wiki/Development-Journal
=======
Virtual Actor
=============

by Carlos Sanchez Witt.

Description
===========

Master Semester Project II, SINLAB/LDM, EPFL.

The goal of this project is to build an emotive virtual actor through implementation of expressive voice synthesis and lip synced mouth animation.

The project is divided in three aspects:

* Text input: the source of speech content, which can be existing literature (formatted for expressive reading), or a social channel with active participation (a Twitter feed for instance).
* Audio output: the voice of the system. The right TTS system must be found for the best emotive speech synthesis.
* Video output: the visual mouth animation, synced to the audio, as a visual stimulus in place of a physical, real actor.

For more information read the wiki at:
https://github.com/sinlab-semester-2013/VirtualActor/wiki

Contents
--------

* VirtualActorJavaProject: application code (Eclipse project)
* marytts: MaryTTS Source Code (Eclipse projects)
* maryxml-input: MaryXML formatted texts for reading by the application

Setup and Dependencies
----------------------

Requires Eclipse/Java, and importing all projects into workspace.

Running Instructions
====================

Run VirtualActorJavaProject from within Eclipse.

Development Status
------------------

See Development Journal at:
https://github.com/sinlab-semester-2013/VirtualActor/wiki/Development-Journal